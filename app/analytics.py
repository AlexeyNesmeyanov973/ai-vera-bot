# app/analytics.py
import re
from collections import Counter
from typing import Dict, List, Tuple

# –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å)
_STOP_RU = {
    "–∏","–≤","–≤–æ","–Ω–∞","—á—Ç–æ","—ç—Ç–æ","–∫–∞–∫","–∫","–∞","–Ω–æ","–∏–ª–∏","–∏–∑","–∑–∞","—Å","—Å–æ","—Ç–æ","—É",
    "–ø–æ","—Ç–∞–∫","–∂–µ","–º—ã","–≤—ã","–æ–Ω","–æ–Ω–∞","–æ–Ω–∏","–æ–Ω–æ","—è","—Ç—ã","–Ω–µ","–¥–∞","–Ω–µ—Ç","–¥–ª—è",
    "–æ—Ç","–¥–æ","–ø—Ä–∏","–Ω–∞–¥","–ø–æ–¥","–ª–∏","–±—ã","–∂–µ","–±—ã–ª–∏","–±—ã–ª","–±—ã–ª–∞","–µ—Å—Ç—å","—Ç–∞–º","–∑–¥–µ—Å—å",
}
_STOP_EN = {
    "the","and","a","an","in","on","at","to","for","of","is","are","was","were","be",
    "been","it","this","that","as","by","or","not","we","you","i","they","he","she",
    "from","with","about","into","over","after","before","but","so","if","then",
}

def _tokenize(text: str) -> List[str]:
    return re.findall(r"[a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9]+", text.lower())

def _sentences(text: str) -> List[str]:
    return [s.strip() for s in re.split(r"[.!?]+", text) if s.strip()]

def _paragraphs(text: str) -> List[str]:
    return [p.strip() for p in text.split("\n\n") if p.strip()]

def analyze_text(text: str, lang_code: str | None = None) -> Dict:
    tokens = _tokenize(text)
    words = [t for t in tokens if t.isalpha()]
    word_count = len(words)
    char_count = len(text)
    sent_count = len(_sentences(text))
    para_count = len(_paragraphs(text))
    unique_words = len(set(words))

    # —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –ø–æ —è–∑—ã–∫—É
    stop = _STOP_EN
    if lang_code and lang_code.lower().startswith("ru"):
        stop = _STOP_RU

    filtered = [w for w in words if w not in stop and len(w) > 2]
    freq = Counter(filtered)
    top_words: List[Tuple[str, int]] = freq.most_common(10)

    # —Å–∫–æ—Ä–æ—Å—Ç—å —á—Ç–µ–Ω–∏—è ~180 —Å–ª–æ–≤/–º–∏–Ω
    reading_time_min = round(word_count / 180.0, 2) if word_count else 0.0

    return {
        "word_count": word_count,
        "unique_words": unique_words,
        "char_count": char_count,
        "sentences": sent_count,
        "paragraphs": para_count,
        "reading_time_min": reading_time_min,
        "top_words": top_words,
    }

def build_report_md(metrics: Dict) -> str:
    lines = [
        "üìä *–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞*",
        f"–°–ª–æ–≤: {metrics.get('word_count', 0)}",
        f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {metrics.get('unique_words', 0)}",
        f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {metrics.get('sentences', 0)}",
        f"–ê–±–∑–∞—Ü–µ–≤: {metrics.get('paragraphs', 0)}",
        f"–í—Ä–µ–º—è —á—Ç–µ–Ω–∏—è: ~{metrics.get('reading_time_min', 0)} –º–∏–Ω",
    ]
    tw = metrics.get("top_words") or []
    if tw:
        lines.append("\n*–¢–æ–ø-—Å–ª–æ–≤–∞:*")
        lines += [f"‚Ä¢ {w} ‚Äî {c}" for w, c in tw]
    return "\n".join(lines)
